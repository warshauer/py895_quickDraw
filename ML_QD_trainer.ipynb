{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working directory: C:\\Users\\Warsh\\ML_Notebooks_edited\\mlqdproj\\proj_notebooks\n",
      "tensorflow version 2.4.0\n"
     ]
    }
   ],
   "source": [
    "#importing way more than we need:\n",
    "import tensorflow.keras,sklearn\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import tensorflow.compat.v1 as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "seed=4\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import requests\n",
    "import io\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter.filedialog import asksaveasfilename\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from numpy import asarray\n",
    "import time\n",
    "import pathlib\n",
    "print('working directory:',pathlib.Path().absolute())\n",
    "#should run on 2.4.0\n",
    "print('tensorflow version',tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QD Trainer Program\n",
    "This is a program put together using scraps from various other notebooks in the course by warsh to make training simple for the group/make sure everyone is on the same page as far as what parts of the dataset are being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded: ['airplane', 'monalisa', 'dragon', 'giraffe', 'axe', 'banana', 'eiffeltower', 'snail', 'windmill', 'snowman']\n"
     ]
    }
   ],
   "source": [
    "all_cat_titles = ['airplane','monalisa','dragon','giraffe','axe','banana','eiffeltower','snail','windmill','snowman','schoolbus','smileyface','lollipop',]\n",
    "\n",
    "img_rows, img_cols = 28, 28 \n",
    "\n",
    "use_dataset_titles = ['X_use','Y_use']\n",
    "ottest = ['ot1','ot2']\n",
    "#DONT YOU DARE TOUCH THE ONLYTEST FILES.\n",
    "#IF YOU ARE TRAINING A NEURAL NETWORK, TRAIN, VALIDATE, AND TEST FROM THE 'USE' FILES.\n",
    "\n",
    "#load data\n",
    "url_main = 'https://physics.bu.edu/~warsh/ML_QD/'\n",
    "datalib={}\n",
    "\n",
    "#loading samples\n",
    "response = requests.get(url_main + use_dataset_titles[0] +'.npy')\n",
    "response.raise_for_status()\n",
    "data = np.load(io.BytesIO(response.content), allow_pickle=False)\n",
    "data = data.reshape(data.shape[0], img_rows*img_cols)\n",
    "datalib[use_dataset_titles[0]] = data\n",
    "\n",
    "response = requests.get(url_main + use_dataset_titles[1] +'.npy')\n",
    "response.raise_for_status()\n",
    "data = np.load(io.BytesIO(response.content), allow_pickle=False)\n",
    "datalib[use_dataset_titles[1]] = data\n",
    "\n",
    "num_classes = int(max(datalib['Y_use'])+1)\n",
    "cat_titles = all_cat_titles[:num_classes]\n",
    "print('loaded:',cat_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an example of a data point with label axe\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an example of a data point with label airplane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (86314, 28, 28, 1)\n",
      "Y_train shape: (86314, 10)\n",
      "X_valid shape: (21578, 28, 28, 1)\n",
      "Y_valid shape: (21578, 10)\n",
      "X_test shape: (26973, 28, 28, 1)\n",
      "Y_test shape: (26973, 10)\n",
      "\n",
      "86314 train samples\n",
      "21578 validation samples\n",
      "26973 test samples\n",
      "134865 total\n"
     ]
    }
   ],
   "source": [
    "#format, delegate, and scale data\n",
    "Y_use = datalib['Y_use']\n",
    "X_use = datalib['X_use']\n",
    "\n",
    "#use small portion, randomized already:\n",
    "ratio_use=.1\n",
    "numosamps = len(Y_use)*ratio_use #number of samples used for train, validation, and testsets\n",
    "test_size=.2 #20% test\n",
    "tr2valr=.8 #64% train, 16% validation\n",
    "num_classes=int(max(Y_use)+1)\n",
    "\n",
    "#scramble and split!\n",
    "X_tr, X_test, Y_tr, Y_test = train_test_split(X_use, Y_use, test_size=test_size, train_size=1.0-test_size)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_tr,Y_tr,train_size=tr2valr,test_size=1-tr2valr)\n",
    "\n",
    "#how much we usin'\n",
    "X_train = X_train[0:int(numosamps*(1.0-test_size)*tr2valr)]\n",
    "Y_train = Y_train[0:int(numosamps*(1.0-test_size)*tr2valr)]\n",
    "X_valid = X_valid[0:int(numosamps*(1.0-test_size)*(1.0-tr2valr))]\n",
    "Y_valid = Y_valid[0:int(numosamps*(1.0-test_size)*(1.0-tr2valr))]\n",
    "X_test = X_test[0:int(numosamps*test_size)]\n",
    "Y_test = Y_test[0:int(numosamps*test_size)]\n",
    "\n",
    "#reshape into 2D\n",
    "X_train = X_train.reshape(X_train.shape[0],img_rows,img_cols)\n",
    "X_valid = X_valid.reshape(X_valid.shape[0],img_rows,img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0],img_rows,img_cols)\n",
    "\n",
    "#yeah okay some floats\n",
    "X_train = X_train.astype('float32')\n",
    "X_valid = X_valid.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "#scale onto the fun zer-O to O-ne inverval\n",
    "X_train /= 255\n",
    "X_valid /= 255\n",
    "X_test /= 255\n",
    "\n",
    "#display some stuff\n",
    "for i in range(2):\n",
    "    print('an example of a data point with label', cat_titles[int(Y_train[i])])\n",
    "    plt.matshow(X_train[i,:],cmap='binary')\n",
    "    plt.show()\n",
    "\n",
    "# converting the actual numbers to the the one-hot vectors\n",
    "Y_train = tensorflow.keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = tensorflow.keras.utils.to_categorical(Y_test, num_classes)\n",
    "Y_valid = tensorflow.keras.utils.to_categorical(Y_valid, num_classes)\n",
    "\n",
    "#reshape data, depending on Keras backend, final data formatting\n",
    "if tensorflow.keras.backend.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    X_valid = X_valid.reshape(X_valid.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    X_valid = X_valid.reshape(X_valid.shape[0], img_rows, img_cols,1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "#more debugging shit\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('X_valid shape:', X_valid.shape)\n",
    "print('Y_valid shape:', Y_valid.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('Y_test shape:', Y_test.shape)\n",
    "print()\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_valid.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "print(X_train.shape[0]+X_valid.shape[0]+X_test.shape[0], 'total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN pulled straight from Prof's NBs, edit this how you like, do whatever you want with your architecture.\n",
    "def create_CNN(nm):\n",
    "    # instantiate model\n",
    "    model = Sequential(name=nm)\n",
    "    # add first convolutional layer with 10 filters (dimensionality of output space)\n",
    "    model.add(Conv2D(10, kernel_size=(5, 5),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    # add 2D pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # add second convolutional layer with 20 filters\n",
    "    model.add(Conv2D(20, (5, 5), activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.25))\n",
    "    # add 2D pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    \n",
    "    \n",
    "    # flatten data\n",
    "    model.add(Flatten())\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(20*4*4, activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.25))\n",
    "    # soft-max layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # compile the model\n",
    "    model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
    "                  optimizer='Adam',\n",
    "                  metrics=['accuracy'])\n",
    "    #lil something special to show us our architecture traits\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pls\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 10)        260       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 20)          5020      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 20)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 20)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 320)               25920     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                3210      \n",
      "=================================================================\n",
      "Total params: 34,410\n",
      "Trainable params: 34,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1349/1349 [==============================] - 15s 11ms/step - loss: 0.8468 - accuracy: 0.7231 - val_loss: 0.3899 - val_accuracy: 0.8928\n",
      "Epoch 2/5\n",
      "1349/1349 [==============================] - 14s 10ms/step - loss: 0.3445 - accuracy: 0.8943 - val_loss: 0.3110 - val_accuracy: 0.9135\n",
      "Epoch 3/5\n",
      "1349/1349 [==============================] - 14s 10ms/step - loss: 0.2962 - accuracy: 0.9123 - val_loss: 0.2874 - val_accuracy: 0.9163\n",
      "Epoch 4/5\n",
      "1349/1349 [==============================] - 14s 11ms/step - loss: 0.2642 - accuracy: 0.9208 - val_loss: 0.2708 - val_accuracy: 0.9264\n",
      "Epoch 5/5\n",
      "1349/1349 [==============================] - 15s 11ms/step - loss: 0.2432 - accuracy: 0.9269 - val_loss: 0.2407 - val_accuracy: 0.9330\n",
      "843/843 [==============================] - 3s 3ms/step - loss: 0.2371 - accuracy: 0.9330\n",
      "\n",
      "Test loss: 0.237104132771492\n",
      "Test accuracy: 0.9330441355705261\n"
     ]
    }
   ],
   "source": [
    "modelname='pls'\n",
    "\n",
    "# training parameters\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "# create the deep conv net\n",
    "model_CNN=create_CNN(modelname)\n",
    "\n",
    "# train CNN\n",
    "model_CNN.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_valid, Y_valid))\n",
    "\n",
    "#evaluate model\n",
    "score = model_CNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk: C:/Users/Warsh/ML_Notebooks_edited/mlqdproj/models/pls.h5\n"
     ]
    }
   ],
   "source": [
    "#save trained model, make sure you have your path set up for this before running, also figure out your filenames\n",
    "#file saving stuff\n",
    "\n",
    "workdir = str(pathlib.Path().absolute())+'\\\\'\n",
    "saveset=True\n",
    "modelName=modelname\n",
    "if saveset==True:\n",
    "    modpath = workdir+modelName\n",
    "    savfil = modpath\n",
    "    i=1\n",
    "    yeet=False\n",
    "    if os.path.exists(savfil+'.h5')==True:\n",
    "        print(savfil+'.h5 already exists, please choose different name')\n",
    "    else:\n",
    "        model_CNN.save(savfil+'.h5')#the last trained model is called model_CNN\n",
    "        yeet=True\n",
    "        print(\"Saved model to disk: \"+savfil+'.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
