{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "warshenstein_dataAug_gridsearch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPcZCS02ipU0"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras,sklearn\n",
        "# suppress tensorflow compilation warnings\n",
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "import tensorflow.compat.v1 as tf\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import numpy as np\n",
        "seed=0\n",
        "np.random.seed(seed) # fix random seed\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras import datasets, layers, models, regularizers\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from urllib.request import urlopen \n",
        "import requests\n",
        "import io\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uajBRqErTjWv"
      },
      "source": [
        "# Grid search for best data augmentation for the preprocessing of Warshenstein's training data\r\n",
        "Performed tested a number of different styles of data augmentation to determine what would give the best result. This is discussed further in the write up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-uJAVngipU5",
        "outputId": "e9811c23-789a-44a3-8e94-ed34ccd70564"
      },
      "source": [
        "all_cat_titles = ['airplane','monalisa','dragon','giraffe','axe','banana','eiffeltower','snail','windmill','snowman','schoolbus','smileyface','lollipop',]\n",
        "\n",
        "img_rows, img_cols = 28, 28 \n",
        "\n",
        "use_dataset_titles = ['X_use','Y_use']\n",
        "ONLYFORFINALCOMPARATIVETEST_DATASETS_DONTYOUFUCKINGTOUCHTHESE = ['X_onlytest','Y_onlytest']\n",
        "#DONT YOU DARE TOUCH THE ONLYTEST FILES.\n",
        "#IF YOU ARE TRAINING A NEURAL NETWORK, TRAIN, VALIDATE, AND TEST FROM THE 'USE' FILES.\n",
        "\n",
        "#load data\n",
        "url_main = 'https://physics.bu.edu/~warsh/ML_QD/'\n",
        "datalib={}\n",
        "\n",
        "#loading samples\n",
        "response = requests.get(url_main + use_dataset_titles[0] +'.npy')\n",
        "response.raise_for_status()\n",
        "data = np.load(io.BytesIO(response.content), allow_pickle=False)\n",
        "data = data.reshape(data.shape[0], img_rows*img_cols)\n",
        "datalib[use_dataset_titles[0]] = data\n",
        "\n",
        "response = requests.get(url_main + use_dataset_titles[1] +'.npy')\n",
        "response.raise_for_status()\n",
        "data = np.load(io.BytesIO(response.content), allow_pickle=False)\n",
        "datalib[use_dataset_titles[1]] = data\n",
        "\n",
        "num_classes = int(max(datalib['Y_use'])+1)\n",
        "cat_titles = all_cat_titles[:num_classes]\n",
        "print('loaded:',cat_titles)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loaded: ['airplane', 'monalisa', 'dragon', 'giraffe', 'axe', 'banana', 'eiffeltower', 'snail', 'windmill', 'snowman']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "3oN_2Nm8ipU6",
        "outputId": "36cc2417-6917-4882-9316-b8c92872c3f0"
      },
      "source": [
        "Y_use = datalib['Y_use']\n",
        "X_use = datalib['X_use']\n",
        "\n",
        "#format, delegate, and scale data\n",
        "ratio_use=.20\n",
        "#use small portion, randomized already:\n",
        "numosamps = len(Y_use)*ratio_use #number of samples used for train, validation, and testsets\n",
        "test_size=.75 #20% test\n",
        "tr2valr=.8 #64% train, 16% validation\n",
        "num_classes=int(max(Y_use)+1)\n",
        "\n",
        "#scramble and split!\n",
        "X_tr, X_test, Y_tr, Y_test = train_test_split(X_use, Y_use, test_size=test_size, train_size=1.0-test_size)\n",
        "X_train, X_valid, Y_train, Y_valid = train_test_split(X_tr,Y_tr,train_size=tr2valr,test_size=1-tr2valr)\n",
        "\n",
        "#how much we usin'\n",
        "X_train = X_train[0:int(numosamps*(1.0-test_size)*tr2valr)]\n",
        "Y_train = Y_train[0:int(numosamps*(1.0-test_size)*tr2valr)]\n",
        "X_valid = X_valid[0:int(numosamps*(1.0-test_size)*(1.0-tr2valr))]\n",
        "Y_valid = Y_valid[0:int(numosamps*(1.0-test_size)*(1.0-tr2valr))]\n",
        "X_test = X_test[0:int(numosamps*test_size)]\n",
        "Y_test = Y_test[0:int(numosamps*test_size)]\n",
        "\n",
        "#reshape into 2D\n",
        "X_train = X_train.reshape(X_train.shape[0],img_rows,img_cols)\n",
        "X_valid = X_valid.reshape(X_valid.shape[0],img_rows,img_cols)\n",
        "X_test = X_test.reshape(X_test.shape[0],img_rows,img_cols)\n",
        "\n",
        "#yeah okay some floats\n",
        "X_train = X_train.astype('float32')\n",
        "X_valid = X_valid.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "#scale onto the fun zer-O to O-ne inverval\n",
        "X_train /= 255\n",
        "X_valid /= 255\n",
        "X_test /= 255\n",
        "\n",
        "X_train_IS = X_train\n",
        "X_valid_IS = X_valid\n",
        "X_test_IS = X_test\n",
        "\n",
        "def channel_and_size(X_t,pv,nchan):\n",
        "    pad=int((pv-28)/2)\n",
        "    npad = ((0, 0), (pad, pad), (pad, pad))\n",
        "    #pad to proper image size - alternatives could be resize up, but I chose just a pad\n",
        "    X_t = np.pad(X_t, pad_width=npad, mode='constant', constant_values=0)\n",
        "    #add channels\n",
        "    X_t = np.stack((X_t,)*nchan, axis=-1)\n",
        "    return X_t\n",
        "\n",
        "#display some stuff\n",
        "for i in range(2):\n",
        "    print('an example of a data point with label', cat_titles[int(Y_train[i])])\n",
        "    plt.matshow(X_train[i,:],cmap='binary')\n",
        "    plt.show()\n",
        "\n",
        "# converting the actual numbers to the the one-hot vectors\n",
        "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
        "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
        "Y_valid = keras.utils.to_categorical(Y_valid, num_classes)\n",
        "\n",
        "#reshape data, depending on Keras backend, final data formatting\n",
        "if keras.backend.image_data_format() == 'channels_first':\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
        "    X_valid = X_valid.reshape(X_valid.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "    X_valid = X_valid.reshape(X_valid.shape[0], img_rows, img_cols,1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "#more debugging shit\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('Y_train shape:', Y_train.shape)\n",
        "print('X_valid shape:', X_valid.shape)\n",
        "print('Y_valid shape:', Y_valid.shape)\n",
        "print('X_test shape:', X_test.shape)\n",
        "print('Y_test shape:', Y_test.shape)\n",
        "print()\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_valid.shape[0], 'validation samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "print(X_train.shape[0]+X_valid.shape[0]+X_test.shape[0], 'total')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "an example of a data point with label windmill\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "an example of a data point with label banana\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAECCAYAAAD+eGJTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPz0lEQVR4nO3dfahV9Z7H8c+3cnpQK+WcVDLHRoSM6h5jU4ZS6XWkKegBIaZSHDAtULrRhSYqyIhCpvQmNAnHsa6h17DUnpspJOpGZHcnopZzzW5aHUyPSdktezC/88fZNqc657eOZ6+91z5+3y+Is8/67IdvK/u01t6/1jZ3F4C4jil6AADFogSA4CgBIDhKAAiOEgCCowSA4AopATO7zMz+ambbzeyOImZIMbMdZrbZzDaaWbkB5nnMzPaY2ZZO2wab2atm9kHl56AGm2+embVV9uFGM7u8wPnOMLPXzOx9M3vPzH5X2d4Q+zAxX132odV7nYCZHStpm6R/lvSppL9Ius7d36/rIAlmtkNSyd33Fj2LJJnZxZL+LukJdz+nsu0/JO1z9/mVIh3k7v/eQPPNk/R3d3+oiJk6M7Nhkoa5+wYzGyjpXUlXS/o3NcA+TMx3reqwD4s4ErhA0nZ3/5u7fy/pSUlXFTBHn+Hub0ja94vNV0laVrm9TB1/aArRzXwNw913ufuGyu2vJG2VdLoaZB8m5quLIkrgdEmfdPr9U9Xxb7iHXNIrZvaumc0uephuDHH3XZXbn0kaUuQw3ZhrZpsqpwuFna50ZmYjJY2VtF4NuA9/MZ9Uh33IG4Ndm+Du50v6F0lzKoe7Dcs7zukabf33YkmjJLVI2iVpQbHjSGY2QNJqSbe6+/7OWSPswy7mq8s+LKIE2iSd0en34ZVtDcPd2yo/90haq45TmEazu3Iueficck/B8/yMu+929x/d/ZCkJSp4H5pZP3X8C7bC3ddUNjfMPuxqvnrtwyJK4C+SRpvZmWb2D5L+VdJzBczRJTPrX3lzRmbWX9IUSVvSjyrEc5JmVG7PkPRsgbP8yuF/uSquUYH70MxM0lJJW919YaeoIfZhd/PVax/W/dMBSap81PGwpGMlPebu99d9iG6Y2T+p47/+knScpD8VPZ+ZrZR0qaQmSbsl3SPpGUmrJI2QtFPSte5eyJtz3cx3qToOY13SDkk3dTr/rvd8EyT9WdJmSYcqm+9Ux3l34fswMd91qsM+LKQEADQO3hgEgqMEgOAoASA4SgAIjhIAgiu0BBp4Sa4k5qtWI8/XyLNJ9Z2v6COBhv4HIearViPP18izSXWcr+gSAFCwqhYLmdllkhapY+Xff7n7/NT9m5qafOTIkT/93t7erubm5l6/fq0xX3Uaeb5Gnk3Kf74dO3Zo79691lV2XG+ftHJxkP9Up4uDmNlzqYuDjBw5UuVy4RfqAcIplUrdZtWcDnBxEOAoUE0J9IWLgwDIUPM3Bs1stpmVzazc3t5e65cDcISqKYEeXRzE3VvdveTupUZ+IwaIqpoSaOiLgwDomV5/OuDuB81srqT/0f9fHOS93CYDUBe9LgFJcveXJL2U0ywACsCKQSA4SgAIjhIAgqMEgOAoASA4SgAIrqqPCIF6+uSTT5L59ddfn8zHjx+fzOfOnZvMhw8fnsz7Ko4EgOAoASA4SgAIjhIAgqMEgOAoASA4SgAIjnUC6DMGDhyYzLOuXLVo0aJk/uabb1aV91UcCQDBUQJAcJQAEBwlAARHCQDBUQJAcJQAEBzrBNBnnHrqqcl8zZo1ybylpaWq5z9acSQABEcJAMFRAkBwlAAQHCUABEcJAMFRAkBwrBPAUWPfvn3JfNOmTcl82rRpeY7TZ1RVAma2Q9JXkn6UdNDdS3kMBaB+8jgSmOjue3N4HgAF4D0BILhqS8AlvWJm75rZ7DwGAlBf1Z4OTHD3NjM7TdKrZva/7v5G5ztUymG2JI0YMaLKlwOQt6qOBNy9rfJzj6S1ki7o4j6t7l5y91LW1WAB1F+vS8DM+pvZwMO3JU2RtCWvwQDURzWnA0MkrTWzw8/zJ3f/71ymAnrhww8/TObunszPOeecPMfpM3pdAu7+N0m/yXEWAAXgI0IgOEoACI4SAIKjBIDgKAEgOEoACI7rCeCoMXz48Koe39bWltMkfQtHAkBwlAAQHCUABEcJAMFRAkBwlAAQHCUABMc6ARw1hg4dmsxPOOGEZL5lS8xr4nAkAARHCQDBUQJAcJQAEBwlAARHCQDBUQJAcKwTwFEj63sFDh06lMwffvjhZP7DDz8k8wcffDCZn3jiicm8KBwJAMFRAkBwlAAQHCUABEcJAMFRAkBwlAAQHOsEcNR47bXXkvn333+fzK+88spkvnjx4mS+bt26ZL5q1apkfu655ybzWsk8EjCzx8xsj5lt6bRtsJm9amYfVH4Oqu2YAGqlJ6cDf5R02S+23SFpnbuPlrSu8juAPiizBNz9DUn7frH5KknLKreXSbo657kA1Elv3xgc4u67Krc/kzQkp3kA1FnVnw54x/+10e3/uWFms82sbGbl9vb2al8OQM56WwK7zWyYJFV+7unuju7e6u4ldy81Nzf38uUA1EpvS+A5STMqt2dIejafcQDUW+Y6ATNbKelSSU1m9qmkeyTNl7TKzGZK2inp2loOCfTE8uXLk3lTU1Myf/rpp5P5+vXrk/n06dOT+ZQpU5L55s2bk3nW/L2VWQLufl030W9zngVAAVg2DARHCQDBUQJAcJQAEBwlAARHCQDBcT0B9BkHDhxI5mvXrk3mWZ/j9+vXL5lPmDAhmb/88svJ/Pzzz0/mN954YzJ/5plnknlvcSQABEcJAMFRAkBwlAAQHCUABEcJAMFRAkBwrBNAn/Hss+lr13z55ZfJ/IYbbshznF8566yzkvlDDz2UzOfMmZPMV69encynTp2azLvDkQAQHCUABEcJAMFRAkBwlAAQHCUABEcJAMGxTgB9Rtb3CowePTqZjxs3Ls9xjtisWbOSedY6gY8++ijPcX7CkQAQHCUABEcJAMFRAkBwlAAQHCUABEcJAMGxTgANo729PZm/8soryfzuu+/Oc5zcZX1vQpaTTjopp0l+LvNIwMweM7M9Zral07Z5ZtZmZhsrf11ek+kA1FxPTgf+KOmyLrb/wd1bKn+9lO9YAOolswTc/Q1J++owC4ACVPPG4Fwz21Q5XRiU20QA6qq3JbBY0ihJLZJ2SVrQ3R3NbLaZlc2snPXGD4D661UJuPtud//R3Q9JWiLpgsR9W9295O6l5ubm3s4JoEZ6VQJmNqzTr9dI2tLdfQE0tsx1Ama2UtKlkprM7FNJ90i61MxaJLmkHZJuquGMCOKRRx5J5gcPHkzmtf5egWpt27atqscPHTo0p0l+LrME3P26LjYvrcEsAArAsmEgOEoACI4SAIKjBIDgKAEgOEoACI7rCaButm7dmswXLOh29bkkafr06cl81KhRRzxTPa1ZsyaZH3/88cl88uTJeY7zE44EgOAoASA4SgAIjhIAgqMEgOAoASA4SgAIrk+tE9i0aVMyHzNmTDLv169fnuOE8/nnnyfzp556Kpnffvvtyfzkk09O5g888EAyL9q3336bzJ988slkPmnSpGSetX96iyMBIDhKAAiOEgCCowSA4CgBIDhKAAiOEgCCa6h1Am+99VYyHz9+fDI/7bTTkvm0adOS+cyZM5P52WefncyLtnHjxmT+0kvpL49+4YUXkvn69euT+aFDh5L5xIkTk/nKlSuT+ZAhQ5J50W655ZZkvnPnzmT++OOP5zlOj3EkAARHCQDBUQJAcJQAEBwlAARHCQDBUQJAcA21TiDrc+YsBw4cSOaPPvpoMl+4cGEyv/DCC5P5iBEjknmWgwcPJvN33nknmbe1tSXzY45Jd37WOoz7778/mV9++eXJ/LzzzkvmjW758uXJfMmSJcn8vvvuS+aXXHLJEc+Uh8wjATM7w8xeM7P3zew9M/tdZftgM3vVzD6o/BxU+3EB5K0npwMHJf3e3c+WNE7SHDM7W9Idkta5+2hJ6yq/A+hjMkvA3Xe5+4bK7a8kbZV0uqSrJC2r3G2ZpKtrNSSA2jmiNwbNbKSksZLWSxri7rsq0WeSGnthN4Au9bgEzGyApNWSbnX3/Z0zd3dJ3s3jZptZ2czK7e3tVQ0LIH89KgEz66eOAljh7oe/WnW3mQ2r5MMk7enqse7e6u4ldy81NzfnMTOAHPXk0wGTtFTSVnfv/Bnac5JmVG7PkPRs/uMBqDXrOJJP3MFsgqQ/S9os6fAH+Xeq432BVZJGSNop6Vp335d6rlKp5OVyudfD3nzzzcl86dKlyfz5559P5tu3b0/mq1evTub79+9P5tXKup7BFVdckcynTJmSzAcPHnzEMx1N3n777WQ+efLkZD5hwoRknnU9h6x1HNUolUoql8vWVZa5WMjd35TU5YMl/baawQAUj2XDQHCUABAcJQAERwkAwVECQHCUABBc5jqBPFW7TuDrr79O5mPHju31c0vShg0bkvmAAQOqen7U1scff5zM77rrrmS+YsWKZH7mmWcm86zvZWhqakrmtZRaJ8CRABAcJQAERwkAwVECQHCUABAcJQAERwkAwTXU9w5k6d+/fzJ/4oknkvnFF1+czLPWGbS2tibziRMnJnOkffHFF8l8/vz5yXzRokXJ/Ljj0n/c77333mR+2223JfOsP5+NiiMBIDhKAAiOEgCCowSA4CgBIDhKAAiOEgCC61PrBLKMGzcumb/++uvJfNasWcl80qRJybylpSWZjx49OpnX2jfffJPMv/vuu6qef+/evcl89+7dybzar6mbOXNmMp83b14yHzp0aFWv31dxJAAERwkAwVECQHCUABAcJQAERwkAwVECQHCZ6wTM7AxJT0gaIskltbr7IjObJ2mWpMMf7t7p7ukvYC/YRRddlMyzvndg6dKlyfzFF19M5tu2bUvmxx57bDKvtVNOOSWZZ82XdV3+8ePHJ/Osz+mnTp2azMeMGZPM0bWeLBY6KOn37r7BzAZKetfMXq1kf3D3h2o3HoBayywBd98laVfl9ldmtlXS6bUeDEB9HNF7AmY2UtJYSYe/b2mumW0ys8fMbFDOswGogx6XgJkNkLRa0q3uvl/SYkmjJLWo40hhQTePm21mZTMrV7s2HED+elQCZtZPHQWwwt3XSJK773b3H939kKQlki7o6rHu3uruJXcvNTc35zU3gJxkloCZmaSlkra6+8JO24d1uts1krbkPx6AWuvJpwPjJU2XtNnMNla23SnpOjNrUcfHhjsk3VSTCQHUlLl73V6sVCp5uVyu2+sB6FAqlVQul62rjBWDQHCUABAcJQAERwkAwVECQHCUABAcJQAERwkAwVECQHCUABAcJQAERwkAwVECQHCUABAcJQAEV9frCZhZu6SdnTY1SUp/qX2xmK86jTxfI88m5T/fP7p7l9f3q2sJ/OrFzcruXipsgAzMV51Gnq+RZ5PqOx+nA0BwlAAQXNEl0Frw62dhvuo08nyNPJtUx/kKfU8AQPGKPhIAUDBKAAiOEgCCowSA4CgBILj/A8PMao8ouXvSAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (53946, 28, 28, 1)\n",
            "Y_train shape: (53946, 10)\n",
            "X_valid shape: (13486, 28, 28, 1)\n",
            "Y_valid shape: (13486, 10)\n",
            "X_test shape: (202300, 28, 28, 1)\n",
            "Y_test shape: (202300, 10)\n",
            "\n",
            "53946 train samples\n",
            "13486 validation samples\n",
            "202300 test samples\n",
            "269732 total\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYVWflA-ipU7"
      },
      "source": [
        "allmodels={}\n",
        "allhistory={}\n",
        "allscores={}\n",
        "\n",
        "#all models evaluated over 10 epochs with batchsize of 256\n",
        "batch=256\n",
        "ep=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH_7XJuWipU6"
      },
      "source": [
        "#data augments for search\n",
        "dataaug_0_noflip = ImageDataGenerator(rotation_range=0,zoom_range = 0,width_shift_range=0,height_shift_range=0, horizontal_flip=False, vertical_flip=False) \n",
        "\n",
        "dataaug_0_flip = ImageDataGenerator(rotation_range=0,zoom_range = 0,width_shift_range=0,height_shift_range=0, horizontal_flip=True, vertical_flip=True) \n",
        "\n",
        "dataaug_4_noflip = ImageDataGenerator(rotation_range=4,zoom_range = 0.04,width_shift_range=0.04,height_shift_range=0.04, horizontal_flip=False, vertical_flip=False) \n",
        "\n",
        "dataaug_4_flip = ImageDataGenerator(rotation_range=4,zoom_range = 0.04,width_shift_range=0.04,height_shift_range=0.04, horizontal_flip=True, vertical_flip=True) \n",
        "\n",
        "dataaug_8_noflip = ImageDataGenerator(rotation_range=8,zoom_range = 0.08,width_shift_range=0.08,height_shift_range=0.08, horizontal_flip=False, vertical_flip=False) \n",
        "\n",
        "dataaug_8_flip = ImageDataGenerator(rotation_range=8,zoom_range = 0.08,width_shift_range=0.08,height_shift_range=0.08, horizontal_flip=True, vertical_flip=True) \n",
        "\n",
        "dataaug_12_noflip = ImageDataGenerator(rotation_range=12,zoom_range = 0.12,width_shift_range=0.12,height_shift_range=0.12, horizontal_flip=False, vertical_flip=False) \n",
        "\n",
        "dataaug_12_flip = ImageDataGenerator(rotation_range=12,zoom_range = 0.12,width_shift_range=0.12,height_shift_range=0.12, horizontal_flip=True, vertical_flip=True) \n",
        "\n",
        "dataaug_16_noflip = ImageDataGenerator(rotation_range=16,zoom_range = 0.16,width_shift_range=0.16,height_shift_range=0.16, horizontal_flip=False, vertical_flip=False) \n",
        "\n",
        "dataaug_16_flip = ImageDataGenerator(rotation_range=16,zoom_range = 0.16,width_shift_range=0.16,height_shift_range=0.16, horizontal_flip=True, vertical_flip=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbUghFeSqmYi"
      },
      "source": [
        "def create_CNN(el1,el2,opti,lays,nm):\r\n",
        "    model = Sequential(name=nm)\r\n",
        "    model.add(Conv2D(lays, kernel_size=(3, 3), activation='relu', input_shape=input_shape,\r\n",
        "                     padding='same', kernel_regularizer=regularizers.l1_l2(l1=el1, l2=el2)))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "    model.add(Conv2D(filters=lays*2, kernel_size = (3,3), activation=\"relu\", \r\n",
        "                     padding='same', kernel_regularizer=regularizers.l1_l2(l1=el1*2, l2=el2*2)))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "    model.add(BatchNormalization())  \r\n",
        "    model.add(Conv2D(filters=lays*2*2, kernel_size = (3,3), activation=\"relu\", \r\n",
        "                     padding='same', kernel_regularizer=regularizers.l1_l2(l1=el1*4, l2=el2*4)))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(BatchNormalization())\r\n",
        "    model.add(Dense(lays*2*2*2,activation=\"relu\"))\r\n",
        "    model.add(Dense(num_classes,activation=\"softmax\"))\r\n",
        "    \r\n",
        "    # compile the model\r\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,\r\n",
        "                  optimizer=opti,\r\n",
        "                  metrics=['accuracy'])\r\n",
        "    \r\n",
        "    #lil something special to show us our architecture traits\r\n",
        "    model.summary()\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvAlG6phHpHg"
      },
      "source": [
        "lays=64\r\n",
        "#found through gridsearch:\r\n",
        "el1=0#.00008 \r\n",
        "el2=0#.000008\r\n",
        "#for gaussian layers:\r\n",
        "noise=0 #well I found adding noise to this actually doesn't help.\r\n",
        "opti='Adam' #gave best results of all optimizers attempted, next best was Adamax."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYrz1bJBipU8",
        "outputId": "b7e61fb1-6993-4f35-9aa9-94d1d986fe17"
      },
      "source": [
        "name='gosh_0_noflip1'\n",
        "train_gen = dataaug_0_noflip.flow(X_train, Y_train, batch_size=batch)\n",
        "test_gen = dataaug_0_noflip.flow(X_test, Y_test, batch_size=batch)\n",
        "valid_gen = dataaug_0_noflip.flow(X_valid, Y_valid, batch_size=batch)\n",
        "\n",
        "allmodels[name] = create_CNN(el1,el2,opti,lays,noise)\n",
        "\n",
        "allhistory[name] = allmodels[name].fit(train_gen, batch_size=batch,epochs=ep,verbose=1,validation_data=(valid_gen))\n",
        "\n",
        "allmodels[name].save(name+'.h5')\n",
        "\n",
        "np.save(name+'_hist_loss.npy',allhistory[name].history['loss'])\n",
        "np.save(name+'_hist_val_loss.npy',allhistory[name].history['val_loss'])\n",
        "np.save(name+'_hist_acc.npy',allhistory[name].history['accuracy'])\n",
        "np.save(name+'_hist_val_acc.npy',allhistory[name].history['val_accuracy'])\n",
        "\n",
        "allscores[name] = allmodels[name].evaluate(X_test,Y_test, verbose=1)\n",
        "print(name + ' acc: %.2f'%allscores[name][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 2304)              9216      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,564,938\n",
            "Trainable params: 1,559,946\n",
            "Non-trainable params: 4,992\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "211/211 [==============================] - 26s 125ms/step - loss: 0.3477 - accuracy: 0.9030 - val_loss: 3.6296 - val_accuracy: 0.2334\n",
            "Epoch 2/10\n",
            "211/211 [==============================] - 27s 128ms/step - loss: 0.1777 - accuracy: 0.9489 - val_loss: 2.2567 - val_accuracy: 0.3008\n",
            "Epoch 3/10\n",
            "211/211 [==============================] - 26s 122ms/step - loss: 0.1095 - accuracy: 0.9663 - val_loss: 0.3552 - val_accuracy: 0.8938\n",
            "Epoch 4/10\n",
            "211/211 [==============================] - 24s 116ms/step - loss: 0.0659 - accuracy: 0.9786 - val_loss: 0.2348 - val_accuracy: 0.9431\n",
            "Epoch 5/10\n",
            "211/211 [==============================] - 25s 118ms/step - loss: 0.0470 - accuracy: 0.9853 - val_loss: 0.2727 - val_accuracy: 0.9432\n",
            "Epoch 6/10\n",
            "211/211 [==============================] - 26s 122ms/step - loss: 0.0332 - accuracy: 0.9890 - val_loss: 0.3140 - val_accuracy: 0.9368\n",
            "Epoch 7/10\n",
            "211/211 [==============================] - 26s 123ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 0.4034 - val_accuracy: 0.9320\n",
            "Epoch 8/10\n",
            "211/211 [==============================] - 26s 122ms/step - loss: 0.0351 - accuracy: 0.9881 - val_loss: 0.3610 - val_accuracy: 0.9360\n",
            "Epoch 9/10\n",
            "211/211 [==============================] - 26s 122ms/step - loss: 0.0460 - accuracy: 0.9853 - val_loss: 0.3088 - val_accuracy: 0.9442\n",
            "Epoch 10/10\n",
            "211/211 [==============================] - 26s 123ms/step - loss: 0.0291 - accuracy: 0.9904 - val_loss: 0.3498 - val_accuracy: 0.9431\n",
            "6322/6322 [==============================] - 48s 8ms/step - loss: 0.3718 - accuracy: 0.9401\n",
            "gosh_0_noflip1 acc: 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubXpHFpuH4u0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f33b5f4-c083-4f1f-d66c-7a87688cc62d"
      },
      "source": [
        "name='gosh_0_flip1'\r\n",
        "train_gen = dataaug_0_flip.flow(X_train, Y_train, batch_size=batch)\r\n",
        "test_gen = dataaug_0_flip.flow(X_test, Y_test, batch_size=batch)\r\n",
        "valid_gen = dataaug_0_flip.flow(X_valid, Y_valid, batch_size=batch)\r\n",
        "\r\n",
        "allmodels[name] = create_CNN(el1,el2,opti,lays,noise)\r\n",
        "\r\n",
        "allhistory[name] = allmodels[name].fit(train_gen, batch_size=batch,epochs=ep,verbose=1,validation_data=(valid_gen))\r\n",
        "\r\n",
        "allmodels[name].save(name+'.h5')\r\n",
        "\r\n",
        "np.save(name+'_hist_loss.npy',allhistory[name].history['loss'])\r\n",
        "np.save(name+'_hist_val_loss.npy',allhistory[name].history['val_loss'])\r\n",
        "np.save(name+'_hist_acc.npy',allhistory[name].history['accuracy'])\r\n",
        "np.save(name+'_hist_val_acc.npy',allhistory[name].history['val_accuracy'])\r\n",
        "\r\n",
        "allscores[name] = allmodels[name].evaluate(X_test,Y_test, verbose=1)\r\n",
        "print(name + ' acc: %.2f'%allscores[name][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 2304)              9216      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,564,938\n",
            "Trainable params: 1,559,946\n",
            "Non-trainable params: 4,992\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "211/211 [==============================] - 27s 128ms/step - loss: 0.4458 - accuracy: 0.8730 - val_loss: 3.4770 - val_accuracy: 0.1898\n",
            "Epoch 2/10\n",
            "211/211 [==============================] - 27s 130ms/step - loss: 0.2682 - accuracy: 0.9250 - val_loss: 2.8946 - val_accuracy: 0.2208\n",
            "Epoch 3/10\n",
            "211/211 [==============================] - 26s 123ms/step - loss: 0.2181 - accuracy: 0.9376 - val_loss: 0.3239 - val_accuracy: 0.9051\n",
            "Epoch 4/10\n",
            "211/211 [==============================] - 27s 126ms/step - loss: 0.1866 - accuracy: 0.9459 - val_loss: 0.2131 - val_accuracy: 0.9385\n",
            "Epoch 5/10\n",
            "211/211 [==============================] - 25s 120ms/step - loss: 0.1672 - accuracy: 0.9512 - val_loss: 0.2007 - val_accuracy: 0.9417\n",
            "Epoch 6/10\n",
            "211/211 [==============================] - 26s 124ms/step - loss: 0.1510 - accuracy: 0.9547 - val_loss: 0.2118 - val_accuracy: 0.9396\n",
            "Epoch 7/10\n",
            "211/211 [==============================] - 27s 127ms/step - loss: 0.1414 - accuracy: 0.9580 - val_loss: 0.2738 - val_accuracy: 0.9215\n",
            "Epoch 8/10\n",
            "211/211 [==============================] - 27s 127ms/step - loss: 0.1291 - accuracy: 0.9608 - val_loss: 0.2186 - val_accuracy: 0.9431\n",
            "Epoch 9/10\n",
            "211/211 [==============================] - 27s 126ms/step - loss: 0.1171 - accuracy: 0.9640 - val_loss: 0.1836 - val_accuracy: 0.9467\n",
            "Epoch 10/10\n",
            "211/211 [==============================] - 27s 129ms/step - loss: 0.1138 - accuracy: 0.9652 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
            "6322/6322 [==============================] - 48s 8ms/step - loss: 0.2080 - accuracy: 0.9459\n",
            "gosh_0_flip1 acc: 0.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lEQpsS8IpX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5b1f0eb-cc70-4f20-f8c3-f81a249124d6"
      },
      "source": [
        "name='gosh_4_noflip1'\r\n",
        "train_gen = dataaug_4_noflip.flow(X_train, Y_train, batch_size=batch)\r\n",
        "test_gen = dataaug_4_noflip.flow(X_test, Y_test, batch_size=batch)\r\n",
        "valid_gen = dataaug_4_noflip.flow(X_valid, Y_valid, batch_size=batch)\r\n",
        "\r\n",
        "allmodels[name] = create_CNN(el1,el2,opti,lays,noise)\r\n",
        "\r\n",
        "allhistory[name] = allmodels[name].fit(train_gen, batch_size=batch,epochs=ep,verbose=1,validation_data=(valid_gen))\r\n",
        "\r\n",
        "allmodels[name].save(name+'.h5')\r\n",
        "\r\n",
        "np.save(name+'_hist_loss.npy',allhistory[name].history['loss'])\r\n",
        "np.save(name+'_hist_val_loss.npy',allhistory[name].history['val_loss'])\r\n",
        "np.save(name+'_hist_acc.npy',allhistory[name].history['accuracy'])\r\n",
        "np.save(name+'_hist_val_acc.npy',allhistory[name].history['val_accuracy'])\r\n",
        "\r\n",
        "allscores[name] = allmodels[name].evaluate(X_test,Y_test, verbose=1)\r\n",
        "print(name + ' acc: %.2f'%allscores[name][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 2304)              9216      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,564,938\n",
            "Trainable params: 1,559,946\n",
            "Non-trainable params: 4,992\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "211/211 [==============================] - 30s 141ms/step - loss: 0.3841 - accuracy: 0.8935 - val_loss: 3.1715 - val_accuracy: 0.2231\n",
            "Epoch 2/10\n",
            "211/211 [==============================] - 31s 146ms/step - loss: 0.2214 - accuracy: 0.9369 - val_loss: 1.1958 - val_accuracy: 0.6943\n",
            "Epoch 3/10\n",
            "211/211 [==============================] - 29s 139ms/step - loss: 0.1786 - accuracy: 0.9472 - val_loss: 0.2988 - val_accuracy: 0.9072\n",
            "Epoch 4/10\n",
            "211/211 [==============================] - 29s 137ms/step - loss: 0.1429 - accuracy: 0.9575 - val_loss: 0.2061 - val_accuracy: 0.9426\n",
            "Epoch 5/10\n",
            "211/211 [==============================] - 29s 137ms/step - loss: 0.1192 - accuracy: 0.9628 - val_loss: 0.2267 - val_accuracy: 0.9410\n",
            "Epoch 6/10\n",
            "211/211 [==============================] - 30s 140ms/step - loss: 0.1012 - accuracy: 0.9681 - val_loss: 0.2599 - val_accuracy: 0.9379\n",
            "Epoch 7/10\n",
            "211/211 [==============================] - 30s 142ms/step - loss: 0.0883 - accuracy: 0.9717 - val_loss: 0.2494 - val_accuracy: 0.9415\n",
            "Epoch 8/10\n",
            "211/211 [==============================] - 30s 140ms/step - loss: 0.0829 - accuracy: 0.9736 - val_loss: 0.2421 - val_accuracy: 0.9436\n",
            "Epoch 9/10\n",
            "211/211 [==============================] - 29s 139ms/step - loss: 0.0697 - accuracy: 0.9773 - val_loss: 0.2249 - val_accuracy: 0.9448\n",
            "Epoch 10/10\n",
            "211/211 [==============================] - 29s 139ms/step - loss: 0.0648 - accuracy: 0.9781 - val_loss: 0.3394 - val_accuracy: 0.9339\n",
            "6322/6322 [==============================] - 50s 8ms/step - loss: 0.3118 - accuracy: 0.9395\n",
            "gosh_4_noflip1 acc: 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcNeTDb8IuRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6bf1df1-d0b4-46b9-ca18-f4ab3d8dcd6e"
      },
      "source": [
        "name='gosh_4_flip1'\r\n",
        "train_gen = dataaug_4_flip.flow(X_train, Y_train, batch_size=batch)\r\n",
        "test_gen = dataaug_4_flip.flow(X_test, Y_test, batch_size=batch)\r\n",
        "valid_gen = dataaug_4_flip.flow(X_valid, Y_valid, batch_size=batch)\r\n",
        "\r\n",
        "allmodels[name] = create_CNN(el1,el2,opti,lays,noise)\r\n",
        "\r\n",
        "allhistory[name] = allmodels[name].fit(train_gen, batch_size=batch,epochs=ep,verbose=1,validation_data=(valid_gen))\r\n",
        "\r\n",
        "allmodels[name].save(name+'.h5')\r\n",
        "\r\n",
        "np.save(name+'_hist_loss.npy',allhistory[name].history['loss'])\r\n",
        "np.save(name+'_hist_val_loss.npy',allhistory[name].history['val_loss'])\r\n",
        "np.save(name+'_hist_acc.npy',allhistory[name].history['accuracy'])\r\n",
        "np.save(name+'_hist_val_acc.npy',allhistory[name].history['val_accuracy'])\r\n",
        "\r\n",
        "allscores[name] = allmodels[name].evaluate(X_test,Y_test, verbose=1)\r\n",
        "print(name + ' acc: %.2f'%allscores[name][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 2304)              9216      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,564,938\n",
            "Trainable params: 1,559,946\n",
            "Non-trainable params: 4,992\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "211/211 [==============================] - 30s 142ms/step - loss: 0.4846 - accuracy: 0.8607 - val_loss: 3.1233 - val_accuracy: 0.2254\n",
            "Epoch 2/10\n",
            "211/211 [==============================] - 29s 139ms/step - loss: 0.2969 - accuracy: 0.9150 - val_loss: 1.8020 - val_accuracy: 0.3302\n",
            "Epoch 3/10\n",
            "211/211 [==============================] - 29s 139ms/step - loss: 0.2472 - accuracy: 0.9306 - val_loss: 0.3082 - val_accuracy: 0.9184\n",
            "Epoch 4/10\n",
            "211/211 [==============================] - 30s 140ms/step - loss: 0.2144 - accuracy: 0.9382 - val_loss: 0.2443 - val_accuracy: 0.9289\n",
            "Epoch 5/10\n",
            "211/211 [==============================] - 29s 139ms/step - loss: 0.1968 - accuracy: 0.9431 - val_loss: 0.2223 - val_accuracy: 0.9356\n",
            "Epoch 6/10\n",
            "211/211 [==============================] - 28s 132ms/step - loss: 0.1861 - accuracy: 0.9456 - val_loss: 0.2188 - val_accuracy: 0.9369\n",
            "Epoch 7/10\n",
            "211/211 [==============================] - 29s 139ms/step - loss: 0.1744 - accuracy: 0.9481 - val_loss: 0.2216 - val_accuracy: 0.9384\n",
            "Epoch 8/10\n",
            "211/211 [==============================] - 29s 139ms/step - loss: 0.1672 - accuracy: 0.9505 - val_loss: 0.2116 - val_accuracy: 0.9402\n",
            "Epoch 9/10\n",
            "211/211 [==============================] - 30s 141ms/step - loss: 0.1601 - accuracy: 0.9513 - val_loss: 0.2308 - val_accuracy: 0.9368\n",
            "Epoch 10/10\n",
            "211/211 [==============================] - 30s 141ms/step - loss: 0.1507 - accuracy: 0.9543 - val_loss: 0.2401 - val_accuracy: 0.9379\n",
            "6322/6322 [==============================] - 51s 8ms/step - loss: 0.2366 - accuracy: 0.9393\n",
            "gosh_4_flip1 acc: 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zOb7wHsIxHP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd73e79-90d1-4801-d16f-12d84d7f85b9"
      },
      "source": [
        "name='gosh_8_noflip1'\r\n",
        "train_gen = dataaug_8_noflip.flow(X_train, Y_train, batch_size=batch)\r\n",
        "test_gen = dataaug_8_noflip.flow(X_test, Y_test, batch_size=batch)\r\n",
        "valid_gen = dataaug_8_noflip.flow(X_valid, Y_valid, batch_size=batch)\r\n",
        "\r\n",
        "allmodels[name] = create_CNN(el1,el2,opti,lays,noise)\r\n",
        "\r\n",
        "allhistory[name] = allmodels[name].fit(train_gen, batch_size=batch,epochs=ep,verbose=1,validation_data=(valid_gen))\r\n",
        "\r\n",
        "allmodels[name].save(name+'.h5')\r\n",
        "\r\n",
        "np.save(name+'_hist_loss.npy',allhistory[name].history['loss'])\r\n",
        "np.save(name+'_hist_val_loss.npy',allhistory[name].history['val_loss'])\r\n",
        "np.save(name+'_hist_acc.npy',allhistory[name].history['accuracy'])\r\n",
        "np.save(name+'_hist_val_acc.npy',allhistory[name].history['val_accuracy'])\r\n",
        "\r\n",
        "allscores[name] = allmodels[name].evaluate(X_test,Y_test, verbose=1)\r\n",
        "print(name + ' acc: %.2f'%allscores[name][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 2304)              9216      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,564,938\n",
            "Trainable params: 1,559,946\n",
            "Non-trainable params: 4,992\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "211/211 [==============================] - 29s 139ms/step - loss: 0.4242 - accuracy: 0.8810 - val_loss: 2.9967 - val_accuracy: 0.1664\n",
            "Epoch 2/10\n",
            "211/211 [==============================] - 29s 138ms/step - loss: 0.2539 - accuracy: 0.9277 - val_loss: 2.3424 - val_accuracy: 0.4190\n",
            "Epoch 3/10\n",
            "211/211 [==============================] - 29s 139ms/step - loss: 0.2126 - accuracy: 0.9386 - val_loss: 0.4013 - val_accuracy: 0.8763\n",
            "Epoch 4/10\n",
            "211/211 [==============================] - 29s 138ms/step - loss: 0.1778 - accuracy: 0.9471 - val_loss: 0.2029 - val_accuracy: 0.9425\n",
            "Epoch 5/10\n",
            "211/211 [==============================] - 30s 140ms/step - loss: 0.1595 - accuracy: 0.9519 - val_loss: 0.1964 - val_accuracy: 0.9422\n",
            "Epoch 6/10\n",
            "211/211 [==============================] - 29s 138ms/step - loss: 0.1477 - accuracy: 0.9545 - val_loss: 0.2211 - val_accuracy: 0.9403\n",
            "Epoch 7/10\n",
            "211/211 [==============================] - 29s 136ms/step - loss: 0.1328 - accuracy: 0.9597 - val_loss: 0.1891 - val_accuracy: 0.9465\n",
            "Epoch 8/10\n",
            "211/211 [==============================] - 29s 137ms/step - loss: 0.1216 - accuracy: 0.9625 - val_loss: 0.2113 - val_accuracy: 0.9373\n",
            "Epoch 9/10\n",
            "211/211 [==============================] - 29s 137ms/step - loss: 0.1137 - accuracy: 0.9634 - val_loss: 0.2048 - val_accuracy: 0.9430\n",
            "Epoch 10/10\n",
            "211/211 [==============================] - 30s 140ms/step - loss: 0.1009 - accuracy: 0.9681 - val_loss: 0.1956 - val_accuracy: 0.9512\n",
            "6322/6322 [==============================] - 48s 8ms/step - loss: 0.1961 - accuracy: 0.9518\n",
            "gosh_8_noflip1 acc: 0.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4hiW3bQIxs7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84b8b9ba-033f-4f23-eac4-6ca02330d2f9"
      },
      "source": [
        "name='gosh_8_flip1'\r\n",
        "train_gen = dataaug_8_flip.flow(X_train, Y_train, batch_size=batch)\r\n",
        "test_gen = dataaug_8_flip.flow(X_test, Y_test, batch_size=batch)\r\n",
        "valid_gen = dataaug_8_flip.flow(X_valid, Y_valid, batch_size=batch)\r\n",
        "\r\n",
        "allmodels[name] = create_CNN(el1,el2,opti,lays,noise)\r\n",
        "\r\n",
        "allhistory[name] = allmodels[name].fit(train_gen, batch_size=batch,epochs=ep,verbose=1,validation_data=(valid_gen))\r\n",
        "\r\n",
        "allmodels[name].save(name+'.h5')\r\n",
        "\r\n",
        "np.save(name+'_hist_loss.npy',allhistory[name].history['loss'])\r\n",
        "np.save(name+'_hist_val_loss.npy',allhistory[name].history['val_loss'])\r\n",
        "np.save(name+'_hist_acc.npy',allhistory[name].history['accuracy'])\r\n",
        "np.save(name+'_hist_val_acc.npy',allhistory[name].history['val_accuracy'])\r\n",
        "\r\n",
        "allscores[name] = allmodels[name].evaluate(X_test,Y_test, verbose=1)\r\n",
        "print(name + ' acc: %.2f'%allscores[name][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_18 (Conv2D)           (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 2304)              9216      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,564,938\n",
            "Trainable params: 1,559,946\n",
            "Non-trainable params: 4,992\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "211/211 [==============================] - 30s 141ms/step - loss: 0.5409 - accuracy: 0.8432 - val_loss: 4.0469 - val_accuracy: 0.1193\n",
            "Epoch 2/10\n",
            "211/211 [==============================] - 30s 142ms/step - loss: 0.3237 - accuracy: 0.9084 - val_loss: 1.9161 - val_accuracy: 0.4364\n",
            "Epoch 3/10\n",
            "211/211 [==============================] - 29s 139ms/step - loss: 0.2705 - accuracy: 0.9226 - val_loss: 0.4790 - val_accuracy: 0.8652\n",
            "Epoch 4/10\n",
            "211/211 [==============================] - 30s 140ms/step - loss: 0.2394 - accuracy: 0.9299 - val_loss: 0.2626 - val_accuracy: 0.9213\n",
            "Epoch 5/10\n",
            "211/211 [==============================] - 30s 142ms/step - loss: 0.2228 - accuracy: 0.9358 - val_loss: 0.2504 - val_accuracy: 0.9241\n",
            "Epoch 6/10\n",
            "211/211 [==============================] - 29s 140ms/step - loss: 0.2046 - accuracy: 0.9396 - val_loss: 0.2395 - val_accuracy: 0.9319\n",
            "Epoch 7/10\n",
            "211/211 [==============================] - 29s 140ms/step - loss: 0.1969 - accuracy: 0.9405 - val_loss: 0.2387 - val_accuracy: 0.9276\n",
            "Epoch 8/10\n",
            "211/211 [==============================] - 30s 140ms/step - loss: 0.1856 - accuracy: 0.9450 - val_loss: 0.2144 - val_accuracy: 0.9381\n",
            "Epoch 9/10\n",
            "211/211 [==============================] - 30s 144ms/step - loss: 0.1794 - accuracy: 0.9470 - val_loss: 0.2315 - val_accuracy: 0.9325\n",
            "Epoch 10/10\n",
            "211/211 [==============================] - 29s 139ms/step - loss: 0.1728 - accuracy: 0.9480 - val_loss: 0.2145 - val_accuracy: 0.9399\n",
            "6322/6322 [==============================] - 50s 8ms/step - loss: 0.1956 - accuracy: 0.9489\n",
            "gosh_8_flip1 acc: 0.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7nt4ClvIyCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44300dac-1bf4-47aa-a277-486afb0da867"
      },
      "source": [
        "name='gosh_12_noflip1'\r\n",
        "train_gen = dataaug_12_noflip.flow(X_train, Y_train, batch_size=batch)\r\n",
        "test_gen = dataaug_12_noflip.flow(X_test, Y_test, batch_size=batch)\r\n",
        "valid_gen = dataaug_12_noflip.flow(X_valid, Y_valid, batch_size=batch)\r\n",
        "\r\n",
        "allmodels[name] = create_CNN(el1,el2,opti,lays,noise)\r\n",
        "\r\n",
        "allhistory[name] = allmodels[name].fit(train_gen, batch_size=batch,epochs=ep,verbose=1,validation_data=(valid_gen))\r\n",
        "\r\n",
        "allmodels[name].save(name+'.h5')\r\n",
        "\r\n",
        "np.save(name+'_hist_loss.npy',allhistory[name].history['loss'])\r\n",
        "np.save(name+'_hist_val_loss.npy',allhistory[name].history['val_loss'])\r\n",
        "np.save(name+'_hist_acc.npy',allhistory[name].history['accuracy'])\r\n",
        "np.save(name+'_hist_val_acc.npy',allhistory[name].history['val_accuracy'])\r\n",
        "\r\n",
        "allscores[name] = allmodels[name].evaluate(X_test,Y_test, verbose=1)\r\n",
        "print(name + ' acc: %.2f'%allscores[name][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 2304)              9216      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,564,938\n",
            "Trainable params: 1,559,946\n",
            "Non-trainable params: 4,992\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "211/211 [==============================] - 30s 143ms/step - loss: 0.4816 - accuracy: 0.8615 - val_loss: 3.6840 - val_accuracy: 0.1838\n",
            "Epoch 2/10\n",
            "211/211 [==============================] - 30s 143ms/step - loss: 0.2859 - accuracy: 0.9180 - val_loss: 2.2005 - val_accuracy: 0.3820\n",
            "Epoch 3/10\n",
            "211/211 [==============================] - 30s 142ms/step - loss: 0.2372 - accuracy: 0.9319 - val_loss: 0.3393 - val_accuracy: 0.8946\n",
            "Epoch 4/10\n",
            "211/211 [==============================] - 30s 143ms/step - loss: 0.2146 - accuracy: 0.9370 - val_loss: 0.2315 - val_accuracy: 0.9320\n",
            "Epoch 5/10\n",
            "211/211 [==============================] - 27s 130ms/step - loss: 0.1900 - accuracy: 0.9441 - val_loss: 0.2093 - val_accuracy: 0.9383\n",
            "Epoch 6/10\n",
            "211/211 [==============================] - 29s 137ms/step - loss: 0.1774 - accuracy: 0.9467 - val_loss: 0.2008 - val_accuracy: 0.9431\n",
            "Epoch 7/10\n",
            "211/211 [==============================] - 30s 140ms/step - loss: 0.1666 - accuracy: 0.9496 - val_loss: 0.2180 - val_accuracy: 0.9336\n",
            "Epoch 8/10\n",
            "211/211 [==============================] - 30s 141ms/step - loss: 0.1559 - accuracy: 0.9521 - val_loss: 0.2423 - val_accuracy: 0.9314\n",
            "Epoch 9/10\n",
            "211/211 [==============================] - 29s 138ms/step - loss: 0.1464 - accuracy: 0.9550 - val_loss: 0.2134 - val_accuracy: 0.9370\n",
            "Epoch 10/10\n",
            "211/211 [==============================] - 30s 140ms/step - loss: 0.1381 - accuracy: 0.9574 - val_loss: 0.2054 - val_accuracy: 0.9382\n",
            "6322/6322 [==============================] - 49s 8ms/step - loss: 0.2646 - accuracy: 0.9291\n",
            "gosh_12_noflip1 acc: 0.93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnQeZHcxIyRN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50554a51-6ff4-4684-ace1-16bdd2d62035"
      },
      "source": [
        "name='gosh_12_flip1'\r\n",
        "train_gen = dataaug_12_flip.flow(X_train, Y_train, batch_size=batch)\r\n",
        "test_gen = dataaug_12_flip.flow(X_test, Y_test, batch_size=batch)\r\n",
        "valid_gen = dataaug_12_flip.flow(X_valid, Y_valid, batch_size=batch)\r\n",
        "\r\n",
        "allmodels[name] = create_CNN(el1,el2,opti,lays,noise)\r\n",
        "\r\n",
        "allhistory[name] = allmodels[name].fit(train_gen, batch_size=batch,epochs=ep,verbose=1,validation_data=(valid_gen))\r\n",
        "\r\n",
        "allmodels[name].save(name+'.h5')\r\n",
        "\r\n",
        "np.save(name+'_hist_loss.npy',allhistory[name].history['loss'])\r\n",
        "np.save(name+'_hist_val_loss.npy',allhistory[name].history['val_loss'])\r\n",
        "np.save(name+'_hist_acc.npy',allhistory[name].history['accuracy'])\r\n",
        "np.save(name+'_hist_val_acc.npy',allhistory[name].history['val_accuracy'])\r\n",
        "\r\n",
        "allscores[name] = allmodels[name].evaluate(X_test,Y_test, verbose=1)\r\n",
        "print(name + ' acc: %.2f'%allscores[name][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_24 (Conv2D)           (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 2304)              9216      \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,564,938\n",
            "Trainable params: 1,559,946\n",
            "Non-trainable params: 4,992\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "211/211 [==============================] - 30s 144ms/step - loss: 0.6099 - accuracy: 0.8195 - val_loss: 4.3747 - val_accuracy: 0.1069\n",
            "Epoch 2/10\n",
            "211/211 [==============================] - 30s 142ms/step - loss: 0.3594 - accuracy: 0.8957 - val_loss: 2.7743 - val_accuracy: 0.2961\n",
            "Epoch 3/10\n",
            "211/211 [==============================] - 29s 140ms/step - loss: 0.3059 - accuracy: 0.9116 - val_loss: 0.7026 - val_accuracy: 0.7793\n",
            "Epoch 4/10\n",
            "211/211 [==============================] - 30s 143ms/step - loss: 0.2697 - accuracy: 0.9207 - val_loss: 0.2631 - val_accuracy: 0.9230\n",
            "Epoch 5/10\n",
            "211/211 [==============================] - 30s 143ms/step - loss: 0.2469 - accuracy: 0.9281 - val_loss: 0.2314 - val_accuracy: 0.9311\n",
            "Epoch 6/10\n",
            "211/211 [==============================] - 31s 148ms/step - loss: 0.2285 - accuracy: 0.9332 - val_loss: 0.2499 - val_accuracy: 0.9230\n",
            "Epoch 7/10\n",
            "211/211 [==============================] - 30s 142ms/step - loss: 0.2226 - accuracy: 0.9346 - val_loss: 0.2223 - val_accuracy: 0.9345\n",
            "Epoch 8/10\n",
            "211/211 [==============================] - 27s 127ms/step - loss: 0.2074 - accuracy: 0.9391 - val_loss: 0.2281 - val_accuracy: 0.9319\n",
            "Epoch 9/10\n",
            "211/211 [==============================] - 27s 127ms/step - loss: 0.2040 - accuracy: 0.9393 - val_loss: 0.2590 - val_accuracy: 0.9235\n",
            "Epoch 10/10\n",
            "211/211 [==============================] - 27s 126ms/step - loss: 0.1944 - accuracy: 0.9417 - val_loss: 0.2623 - val_accuracy: 0.9239\n",
            "6322/6322 [==============================] - 43s 7ms/step - loss: 0.2278 - accuracy: 0.9376\n",
            "gosh_12_flip1 acc: 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6WLyo14ipU-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2328d4b-3531-47ff-9cd3-3b2bf52b9e47"
      },
      "source": [
        "name='gosh_16_noflip1'\r\n",
        "train_gen = dataaug_16_noflip.flow(X_train, Y_train, batch_size=batch)\r\n",
        "test_gen = dataaug_16_noflip.flow(X_test, Y_test, batch_size=batch)\r\n",
        "valid_gen = dataaug_16_noflip.flow(X_valid, Y_valid, batch_size=batch)\r\n",
        "\r\n",
        "allmodels[name] = create_CNN(el1,el2,opti,lays,noise)\r\n",
        "\r\n",
        "allhistory[name] = allmodels[name].fit(train_gen, batch_size=batch,epochs=ep,verbose=1,validation_data=(valid_gen))\r\n",
        "\r\n",
        "allmodels[name].save(name+'.h5')\r\n",
        "\r\n",
        "np.save(name+'_hist_loss.npy',allhistory[name].history['loss'])\r\n",
        "np.save(name+'_hist_val_loss.npy',allhistory[name].history['val_loss'])\r\n",
        "np.save(name+'_hist_acc.npy',allhistory[name].history['accuracy'])\r\n",
        "np.save(name+'_hist_val_acc.npy',allhistory[name].history['val_accuracy'])\r\n",
        "\r\n",
        "allscores[name] = allmodels[name].evaluate(X_test,Y_test, verbose=1)\r\n",
        "print(name + ' acc: %.2f'%allscores[name][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_27 (Conv2D)           (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 2304)              9216      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,564,938\n",
            "Trainable params: 1,559,946\n",
            "Non-trainable params: 4,992\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "211/211 [==============================] - 27s 129ms/step - loss: 0.5570 - accuracy: 0.8374 - val_loss: 3.8826 - val_accuracy: 0.1838\n",
            "Epoch 2/10\n",
            "211/211 [==============================] - 27s 126ms/step - loss: 0.3328 - accuracy: 0.9046 - val_loss: 2.6267 - val_accuracy: 0.2850\n",
            "Epoch 3/10\n",
            "211/211 [==============================] - 27s 128ms/step - loss: 0.2713 - accuracy: 0.9206 - val_loss: 0.5649 - val_accuracy: 0.8188\n",
            "Epoch 4/10\n",
            "211/211 [==============================] - 27s 127ms/step - loss: 0.2454 - accuracy: 0.9286 - val_loss: 0.2821 - val_accuracy: 0.9165\n",
            "Epoch 5/10\n",
            "211/211 [==============================] - 27s 127ms/step - loss: 0.2188 - accuracy: 0.9349 - val_loss: 0.2610 - val_accuracy: 0.9258\n",
            "Epoch 6/10\n",
            "211/211 [==============================] - 28s 132ms/step - loss: 0.2039 - accuracy: 0.9391 - val_loss: 0.2373 - val_accuracy: 0.9281\n",
            "Epoch 7/10\n",
            "211/211 [==============================] - 27s 127ms/step - loss: 0.1934 - accuracy: 0.9427 - val_loss: 0.2614 - val_accuracy: 0.9210\n",
            "Epoch 8/10\n",
            "211/211 [==============================] - 27s 128ms/step - loss: 0.1818 - accuracy: 0.9449 - val_loss: 0.2132 - val_accuracy: 0.9360\n",
            "Epoch 9/10\n",
            "211/211 [==============================] - 27s 127ms/step - loss: 0.1772 - accuracy: 0.9475 - val_loss: 0.2773 - val_accuracy: 0.9234\n",
            "Epoch 10/10\n",
            "211/211 [==============================] - 27s 126ms/step - loss: 0.1688 - accuracy: 0.9498 - val_loss: 0.2125 - val_accuracy: 0.9424\n",
            "6322/6322 [==============================] - 43s 7ms/step - loss: 0.2520 - accuracy: 0.9419\n",
            "gosh_16_noflip1 acc: 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq7s3tysSlH5",
        "outputId": "c5240208-b31e-48ae-cc75-11e4b0b7c36e"
      },
      "source": [
        "name='gosh_16_flip1'\r\n",
        "train_gen = dataaug_16_flip.flow(X_train, Y_train, batch_size=batch)\r\n",
        "test_gen = dataaug_16_flip.flow(X_test, Y_test, batch_size=batch)\r\n",
        "valid_gen = dataaug_16_flip.flow(X_valid, Y_valid, batch_size=batch)\r\n",
        "\r\n",
        "allmodels[name] = create_CNN(el1,el2,opti,lays,noise)\r\n",
        "\r\n",
        "allhistory[name] = allmodels[name].fit(train_gen, batch_size=batch,epochs=ep,verbose=1,validation_data=(valid_gen))\r\n",
        "\r\n",
        "allmodels[name].save(name+'.h5')\r\n",
        "\r\n",
        "np.save(name+'_hist_loss.npy',allhistory[name].history['loss'])\r\n",
        "np.save(name+'_hist_val_loss.npy',allhistory[name].history['val_loss'])\r\n",
        "np.save(name+'_hist_acc.npy',allhistory[name].history['accuracy'])\r\n",
        "np.save(name+'_hist_val_acc.npy',allhistory[name].history['val_accuracy'])\r\n",
        "\r\n",
        "allscores[name] = allmodels[name].evaluate(X_test,Y_test, verbose=1)\r\n",
        "print(name + ' acc: %.2f'%allscores[name][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_30 (Conv2D)           (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 2304)              9216      \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,564,938\n",
            "Trainable params: 1,559,946\n",
            "Non-trainable params: 4,992\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "211/211 [==============================] - 28s 132ms/step - loss: 0.7051 - accuracy: 0.7893 - val_loss: 7.0677 - val_accuracy: 0.1838\n",
            "Epoch 2/10\n",
            "211/211 [==============================] - 27s 130ms/step - loss: 0.4112 - accuracy: 0.8779 - val_loss: 4.7868 - val_accuracy: 0.2174\n",
            "Epoch 3/10\n",
            "211/211 [==============================] - 27s 130ms/step - loss: 0.3455 - accuracy: 0.8995 - val_loss: 0.8413 - val_accuracy: 0.7173\n",
            "Epoch 4/10\n",
            "211/211 [==============================] - 28s 130ms/step - loss: 0.3056 - accuracy: 0.9117 - val_loss: 0.3213 - val_accuracy: 0.9008\n",
            "Epoch 5/10\n",
            "211/211 [==============================] - 28s 131ms/step - loss: 0.2826 - accuracy: 0.9181 - val_loss: 0.2918 - val_accuracy: 0.9106\n",
            "Epoch 6/10\n",
            "211/211 [==============================] - 28s 132ms/step - loss: 0.2644 - accuracy: 0.9239 - val_loss: 0.3209 - val_accuracy: 0.9074\n",
            "Epoch 7/10\n",
            "211/211 [==============================] - 27s 130ms/step - loss: 0.2501 - accuracy: 0.9266 - val_loss: 0.3165 - val_accuracy: 0.9081\n",
            "Epoch 8/10\n",
            "211/211 [==============================] - 27s 129ms/step - loss: 0.2377 - accuracy: 0.9292 - val_loss: 0.3047 - val_accuracy: 0.9096\n",
            "Epoch 9/10\n",
            "211/211 [==============================] - 27s 130ms/step - loss: 0.2279 - accuracy: 0.9335 - val_loss: 0.2534 - val_accuracy: 0.9238\n",
            "Epoch 10/10\n",
            "211/211 [==============================] - 27s 129ms/step - loss: 0.2222 - accuracy: 0.9342 - val_loss: 0.3051 - val_accuracy: 0.9049\n",
            "6322/6322 [==============================] - 44s 7ms/step - loss: 0.3169 - accuracy: 0.8988\n",
            "gosh_16_flip1 acc: 0.90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfgsIGm5So36",
        "outputId": "dc15e8ab-5051-468a-fa5d-206406bad8f0"
      },
      "source": [
        "for key in allscores.keys():\r\n",
        "  print(key, allscores[key])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gosh_0_flip1 [0.22322270274162292, 0.9426299929618835]\n",
            "gosh_0_noflip1 [0.3908435106277466, 0.9335799813270569]\n",
            "gosh_4_noflip1 [0.27500563859939575, 0.9407600164413452]\n",
            "gosh_4_flip1 [0.21606098115444183, 0.9425299763679504]\n",
            "gosh_8_noflip1 [0.22192451357841492, 0.9444500207901001]\n",
            "gosh_8_flip1 [0.2127154916524887, 0.9396100044250488]\n",
            "gosh_12_noflip1 [0.2082834392786026, 0.9514300227165222]\n",
            "gosh_12_flip1 [0.28100690245628357, 0.9290500283241272]\n",
            "gosh_16_noflip1 [0.22161875665187836, 0.9415500164031982]\n",
            "gosh_16_flip1 [0.3211497366428375, 0.9097300171852112]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7guIm4GQV6H0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
